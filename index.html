<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Audio to Text Converter</title>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap" rel="stylesheet">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        body {
            font-family: 'Inter', Arial, sans-serif;
            background: linear-gradient(135deg, #e0e7ff 0%, #f3e8ff 100%);
            min-height: 100vh;
            display: flex;
            flex-direction: column;
            align-items: center;
            padding: 20px;
        }
        h1 {
            color: #1e3a8a;
            font-size: 2.5rem;
            font-weight: 700;
            margin-bottom: 20px;
            text-align: center;
        }
        .container {
            background: white;
            border-radius: 16px;
            box-shadow: 0 8px 24px rgba(0, 0, 0, 0.1);
            max-width: 900px;
            width: 100%;
            padding: 30px;
            margin: 0 auto;
        }
        .input-section {
            display: flex;
            flex-direction: column;
            gap: 20px;
            margin-bottom: 30px;
        }
        .file-input, .record-button {
            display: flex;
            align-items: center;
            gap: 15px;
            flex-wrap: wrap;
        }
        input[type="file"] {
            padding: 12px;
            border: 2px dashed #cbd5e1;
            border-radius: 8px;
            font-size: 1rem;
            background: #f8fafc;
            cursor: pointer;
            transition: border-color 0.3s;
        }
        input[type="file"]:hover {
            border-color: #3b82f6;
        }
        button {
            padding: 12px 24px;
            font-size: 1rem;
            font-weight: 600;
            color: white;
            background: linear-gradient(90deg, #3b82f6, #7c3aed);
            border: none;
            border-radius: 8px;
            cursor: pointer;
            transition: transform 0.2s, box-shadow 0.2s;
        }
        button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
        }
        .record-button button.recording {
            background: linear-gradient(90deg, #e11d48, #9f1239);
        }
        .record-button button.recording:hover {
            background: linear-gradient(90deg, #be123c, #881337);
        }
        .status {
            text-align: center;
            color: #64748b;
            font-size: 1rem;
            font-style: italic;
            margin: 20px 0;
        }
        textarea {
            width: 100%;
            height: 250px;
            padding: 15px;
            border: 1px solid #e2e8f0;
            border-radius: 8px;
            font-size: 1rem;
            background: #f8fafc;
            resize: vertical;
            transition: border-color 0.3s;
        }
        textarea:focus {
            outline: none;
            border-color: #3b82f6;
            box-shadow: 0 0 0 3px rgba(59, 130, 246, 0.1);
        }
        .footer {
            margin-top: 20px;
            text-align: center;
            color: #64748b;
            font-size: 0.9rem;
        }
        @media (max-width: 600px) {
            h1 {
                font-size: 1.8rem;
            }
            .container {
                padding: 20px;
            }
            input[type="file"], button {
                font-size: 0.9rem;
                padding: 10px;
            }
            textarea {
                height: 200px;
            }
            .file-input, .record-button {
                flex-direction: column;
                align-items: stretch;
            }
        }
    </style>
</head>
<body>
    <h1>Audio to Text Converter</h1>
    <div class="container">
        <div class="input-section">
            <div class="file-input">
                <input type="file" id="audioInput" accept="audio/*">
                <button onclick="uploadAudio()">Upload Audio</button>
            </div>
            <div class="record-button">
                <button id="recordButton" onclick="toggleRecording()">Transcribe</button>
            </div>
        </div>
        <div id="status" class="status">No audio processed yet</div>
        <textarea id="transcriptionOutput" placeholder="Your transcribed text will appear here..." readonly></textarea>
    </div>
    <div class="footer">Powered by your creativity</div>

    <script src="https://cdn.jsdelivr.net/npm/@ffmpeg/ffmpeg@0.11.6/dist/ffmpeg.min.js"></script>
    <script>
        // Hugging Face API configuration
        const HF_API_TOKEN = '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'; // Replace with your token
        const HF_API_URL = 'https://api-inference.huggingface.co/models/facebook/wav2vec2-base-960h';

        // FFmpeg for audio conversion
        const { createFFmpeg, fetchFile } = FFmpeg;
        const ffmpeg = createFFmpeg({ log: false });
        let isRecording = false;
        let mediaRecorder;
        let audioChunks = [];

        // Update status
        function setStatus(message) {
            document.getElementById('status').textContent = message;
        }

        // Convert audio to WAV using FFmpeg
        async function convertToWav(audioBlob) {
            if (!ffmpeg.isLoaded()) await ffmpeg.load();
            const inputName = 'input_audio';
            const outputName = 'output.wav';
            ffmpeg.FS('writeFile', inputName, await fetchFile(audioBlob));
            await ffmpeg.run('-i', inputName, '-acodec', 'pcm_s16le', '-ar', '16000', '-ac', '1', outputName);
            const output = ffmpeg.FS('readFile', outputName);
            return new Blob([output.buffer], { type: 'audio/wav' });
        }

        // Transcribe audio using Hugging Face API
        async function transcribeAudio(audioBlob) {
            setStatus('Transcribing...');
            try {
                const wavBlob = await convertToWav(audioBlob);
                const formData = new FormData();
                formData.append('audio', wavBlob, 'audio.wav');
                
                const response = await fetch(HF_API_URL, {
                    method: 'POST',
                    headers: {
                        'Authorization': `Bearer ${HF_API_TOKEN}`
                    },
                    body: wavBlob
                });
                const result = await response.json();
                if (result.error) {
                    throw new Error(result.error);
                }
                const transcription = result.text || 'No transcription available';
                document.getElementById('transcriptionOutput').value = transcription;
                setStatus('Transcription complete');
            } catch (error) {
                console.error('Transcription error:', error);
                setStatus('Error during transcription');
                document.getElementById('transcriptionOutput').value = 'Error: Could not transcribe audio';
            }
        }

        // Handle file upload
        async function uploadAudio() {
            const input = document.getElementById('audioInput');
            if (input.files.length === 0) {
                setStatus('Please select an audio file');
                return;
            }
            const file = input.files[0];
            await transcribeAudio(file);
        }

        // Handle recording
        async function toggleRecording() {
            const recordButton = document.getElementById('recordButton');
            if (!isRecording) {
                try {
                    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                    mediaRecorder = new MediaRecorder(stream);
                    audioChunks = [];
                    mediaRecorder.ondataavailable = (e) => audioChunks.push(e.data);
                    mediaRecorder.onstop = async () => {
                        const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                        await transcribeAudio(audioBlob);
                        stream.getTracks().forEach(track => track.stop());
                    };
                    mediaRecorder.start();
                    isRecording = true;
                    recordButton.textContent = 'Stop Transcription';
                    recordButton.classList.add('recording');
                    setStatus('Recording...');
                } catch (error) {
                    console.error('Recording error:', error);
                    setStatus('Error accessing microphone');
                }
            } else {
                mediaRecorder.stop();
                isRecording = false;
                recordButton.textContent = 'Transcribe';
                recordButton.classList.remove('recording');
            }
        }
    </script>
</body>
</html>
